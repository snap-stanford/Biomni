import chainlit as cl
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from biomni.agent import A1_HITS
from langchain_core.messages import (
    AIMessage,
    AIMessageChunk,
    HumanMessage,
    SystemMessage,
)
import os
import re
import shutil
import random
import string
import base64
import io
import wave
import struct
import audioop
import numpy as np
from PIL import Image
from biomni.config import default_config
from biomni.tool.memory import save_conversation
from chainlit.data.sql_alchemy import SQLAlchemyDataLayer
from chainlit.data.storage_clients.base import BaseStorageClient
from sqlalchemy import create_engine, event
from sqlalchemy.ext.asyncio import (
    create_async_engine,
    AsyncEngine,
    AsyncSession,
    async_sessionmaker,
)
import asyncio
import logging
import concurrent.futures
from openai import OpenAI

# OpenAI client for Whisper API (Speech-to-Text)
openai_client = OpenAI()

# Audio silence detection settings
SILENCE_THRESHOLD = 2000  # RMS threshold for silence detection (lower = more sensitive)
SILENCE_TIMEOUT_MS = 1500  # Milliseconds of silence before auto-stopping (1.5 seconds)

CURRENT_ABS_DIR = os.path.dirname(os.path.abspath(__file__))


def _resolve_biomni_data_path() -> str:
    """Determine the local biomni data path, preferring existing directories."""
    candidates = []
    for env_key in ("BIOMNI_DATA_PATH", "BIOMNI_PATH"):
        env_value = os.getenv(env_key)
        if env_value:
            candidates.append(env_value)

    # Known shared locations and repo-relative defaults
    candidates.extend(
        [
            "/workdir_efs/jhjeon/Biomni/biomni_data",
            os.path.join(CURRENT_ABS_DIR, "..", "biomni_data"),
            os.path.join(CURRENT_ABS_DIR, "biomni_data"),
        ]
    )

    seen = set()
    for candidate in candidates:
        if not candidate:
            continue
        abs_candidate = os.path.abspath(candidate)
        if abs_candidate in seen:
            continue
        seen.add(abs_candidate)
        if os.path.isdir(abs_candidate):
            return abs_candidate

    fallback = os.path.abspath(os.path.join(CURRENT_ABS_DIR, "..", "biomni_data"))
    os.makedirs(fallback, exist_ok=True)
    return fallback


# Configuration
LLM_MODEL = "gemini-3-pro-preview"
# LLM_MODEL = "grok-4-fast"
BIOMNI_DATA_PATH = _resolve_biomni_data_path()
PUBLIC_DIR = os.path.join(os.getcwd(), "public")
CHAINLIT_DB_PATH = os.path.join(CURRENT_ABS_DIR, "chainlit.db")
STREAMING_MAX_TIMEOUT = 3600  # Maximum streaming timeout in seconds (1 hour)

default_config.llm = LLM_MODEL
default_config.commercial_mode = True
# Initialize agent
agent = A1_HITS(
    path=BIOMNI_DATA_PATH,
    llm=LLM_MODEL,
    use_tool_retriever=True,
    resource_filter_config_path=f"{CURRENT_ABS_DIR}/resource.yaml",
)

# ë¡œê¹… ì„¤ì •
LOG_FILE_PATH = f"{CURRENT_ABS_DIR}/chainlit_stream.log"

# Create logger and set up handlers directly
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Remove any existing handlers to avoid duplicates
logger.handlers.clear()

# Create and configure handlers
formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")

# Console handler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

# File handler for global log
file_handler = logging.FileHandler(LOG_FILE_PATH, mode="a")
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# Prevent propagation to root logger to avoid duplicate logs
logger.propagate = False

logger.info(f"Logger initialized. Log file: {LOG_FILE_PATH}")

# Thread-specific log handler management
_thread_log_handler = None


def add_thread_log_handler(thread_id: str):
    """Add a thread-specific log handler to capture logs for individual chat sessions.

    Args:
        thread_id: The unique thread/session identifier
    """
    global _thread_log_handler

    # Remove previous thread-specific handler if exists
    if _thread_log_handler:
        logger.removeHandler(_thread_log_handler)
        _thread_log_handler.close()

    # Create new thread-specific log file
    thread_log_path = f"{CURRENT_ABS_DIR}/chainlit_logs/{thread_id}/chainlit_stream.log"
    os.makedirs(os.path.dirname(thread_log_path), exist_ok=True)

    # Add new handler for this thread
    _thread_log_handler = logging.FileHandler(thread_log_path, mode="a")
    _thread_log_handler.setLevel(logging.INFO)
    _thread_log_handler.setFormatter(
        logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    )
    logger.addHandler(_thread_log_handler)

    logger.info(f"Thread-specific log handler added for thread: {thread_id}")
    logger.info(f"Thread log file: {thread_log_path}")


class LocalStorageClient(BaseStorageClient):
    """ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì— íŒŒì¼ì„ ì €ì¥í•˜ëŠ” ìŠ¤í† ë¦¬ì§€ í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, storage_dir: str = None):
        """
        Args:
            storage_dir: íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: PUBLIC_DIR)
        """
        if storage_dir is None:
            storage_dir = PUBLIC_DIR
        self.storage_dir = os.path.abspath(storage_dir)
        os.makedirs(self.storage_dir, exist_ok=True)

    async def upload_file(
        self,
        object_key: str,
        data: bytes | str,
        mime: str = "application/octet-stream",
        overwrite: bool = True,
        content_disposition: str | None = None,
    ) -> dict:
        """íŒŒì¼ì„ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì— ì—…ë¡œë“œ"""
        file_path = os.path.join(self.storage_dir, object_key)
        os.makedirs(os.path.dirname(file_path), exist_ok=True)

        if isinstance(data, str):
            data = data.encode("utf-8")

        with open(file_path, "wb") as f:
            f.write(data)

        return {
            "object_key": object_key,
            "path": file_path,
            "url": f"/public/{object_key}",
        }

    async def delete_file(self, object_key: str) -> bool:
        """íŒŒì¼ ì‚­ì œ"""
        file_path = os.path.join(self.storage_dir, object_key)
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                return True
            return False
        except Exception as e:
            logger.error(f"Failed to delete file {object_key}: {e}")
            return False

    async def get_read_url(self, object_key: str) -> str:
        """íŒŒì¼ ì½ê¸° URL ë°˜í™˜"""
        return f"/public/{object_key}"

    async def close(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œëŠ” í•„ìš” ì—†ìŒ)"""
        pass


class CustomSQLAlchemyDataLayer(SQLAlchemyDataLayer):
    def __init__(self, conninfo: str, **kwargs):
        super().__init__(conninfo, **kwargs)

        self.engine: AsyncEngine = create_async_engine(
            conninfo,
            pool_size=100,  # SQLiteëŠ” ë‹¨ì¼ ì—°ê²°ì´ íš¨ìœ¨ì 
            max_overflow=200,  # ì˜¤ë²„í”Œë¡œìš° ë°©ì§€
            pool_timeout=60,  # 60ì´ˆ ëŒ€ê¸°
            pool_recycle=3600,  # 1ì‹œê°„ë§ˆë‹¤ ì—°ê²° ì¬ìƒì„±
            pool_pre_ping=True,  # ì—°ê²° ìƒíƒœ í™•ì¸
            echo=False,  # SQL ë¡œê¹… ë¹„í™œì„±í™”
            connect_args={
                "timeout": 30,  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                "check_same_thread": False,  # ë©€í‹°ìŠ¤ë ˆë“œ í—ˆìš©
            },
        )

        self.async_session = async_sessionmaker(
            bind=self.engine,
            expire_on_commit=False,  # ì„±ëŠ¥ í–¥ìƒ ë° lock ì‹œê°„ ë‹¨ì¶•
            class_=AsyncSession,
            autoflush=False,  # ìë™ í”ŒëŸ¬ì‹œ ë¹„í™œì„±í™”ë¡œ ì„±ëŠ¥ í–¥ìƒ
        )

        # ì¬ì‹œë„ ì„¤ì •
        self.max_retries = 5
        self.retry_delay = 0.1  # 100ms

    async def __aenter__(self):
        # SQLite ìµœì í™” ì„¤ì •
        @event.listens_for(self.engine.sync_engine, "connect")
        def set_sqlite_pragma(dbapi_connection, connection_record):
            cursor = dbapi_connection.cursor()
            # WAL ëª¨ë“œ í™œì„±í™” (ë™ì‹œì„± ê°œì„ )
            cursor.execute("PRAGMA journal_mode=WAL")
            # ë°”ìœ íƒ€ì„ì•„ì›ƒ ì„¤ì • (60ì´ˆë¡œ ì¦ê°€)
            cursor.execute("PRAGMA busy_timeout=60000")
            # ë™ê¸°í™” ëª¨ë“œ ìµœì í™” (NORMALë³´ë‹¤ ì•ˆì „í•œ FULL ì‚¬ìš©)
            cursor.execute("PRAGMA synchronous=FULL")
            # ìºì‹œ í¬ê¸° ì¦ê°€
            cursor.execute("PRAGMA cache_size=20000")
            # WAL ìë™ ì²´í¬í¬ì¸íŠ¸ ì„¤ì • (ë” ìì£¼ ì²´í¬í¬ì¸íŠ¸)
            cursor.execute("PRAGMA wal_autocheckpoint=500")
            # ì„ì‹œ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥
            cursor.execute("PRAGMA temp_store=MEMORY")
            # ë©”ëª¨ë¦¬ ë§µí•‘ í¬ê¸° ì„¤ì • (256MB)
            cursor.execute("PRAGMA mmap_size=268435456")
            # ì™¸ë˜í‚¤ ì œì•½ ì¡°ê±´ ë¹„í™œì„±í™” (ì„±ëŠ¥ í–¥ìƒ)
            cursor.execute("PRAGMA foreign_keys=OFF")
            # ë½ íƒ€ì„ì•„ì›ƒ ì¶”ê°€ ì„¤ì •
            cursor.execute("PRAGMA lock_timeout=60000")
            # WAL ëª¨ë“œì—ì„œ ì½ê¸° ì„±ëŠ¥ í–¥ìƒ
            cursor.execute("PRAGMA read_uncommitted=1")
            cursor.close()

        return await super().__aenter__()


@cl.data_layer
def get_data_layer():
    # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ì„¤ì •
    db_path = os.path.abspath(CHAINLIT_DB_PATH)
    conninfo = f"sqlite+aiosqlite:///{db_path}"
    print(f"Chainlit database path: {db_path}")

    # ìŠ¤í† ë¦¬ì§€ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (íŒŒì¼ ì €ì¥ìš©)
    storage_provider = LocalStorageClient()

    return CustomSQLAlchemyDataLayer(
        conninfo=conninfo, storage_provider=storage_provider, show_logger=False
    )


@cl.password_auth_callback
def auth_callback(username: str, password: str):
    # Fetch the user matching username from your database
    # and compare the hashed password with the value stored in the database
    # Support both username and email format for login
    valid_logins = {
        ("admin", "admin"): "admin",
        ("admin@example.com", "admin"): "admin@example.com",
        ("admin@biomni.com", "admin"): "admin@biomni.com",
        ("jslink", "5fdf7e4a-6632-48b1-a9c8-b79d9a9be2e0"): "jslink",
    }

    identifier = valid_logins.get((username, password))

    if identifier:
        return cl.User(
            identifier=identifier,  # ê° ì‚¬ìš©ìë§ˆë‹¤ ê³ ìœ í•œ identifier ì‚¬ìš©
            metadata={"role": "admin", "provider": "credentials"},
        )
    else:
        return None


@cl.on_chat_start
async def start_chat():
    """Initialize chat session and set up working directory."""
    os.chdir(CURRENT_ABS_DIR)
    dir_name = cl.context.session.thread_id
    log_dir = f"chainlit_logs/{dir_name}"
    os.makedirs(log_dir, exist_ok=True)

    # Add thread-specific log handler
    add_thread_log_handler(dir_name)

    os.chdir(log_dir)
    print("current dir", os.getcwd())
    logger.info(f"Chat session started for thread: {dir_name}")
    cl.user_session.set("message_history", [])
    cl.user_session.set("uploaded_files", [])

    files = None

    # # Wait for the user to upload a file
    # while files == None:
    #     files = await cl.AskFileMessage(
    #         content="Please upload your omics data to analyze!",
    #         accept=["*/*"],
    #         max_size_mb=800,
    #         max_files=10,
    #     ).send()

    # # Show loading indicator while copying file
    # user_uploaded_system_file = ""
    # uploading_status_message = ""
    # async with cl.Step(name=f"Processing files...") as step:
    #     for file in files:
    #         step.output = (
    #             uploading_status_message
    #             + f"Uploading file: {file.name} ({file.size} bytes)..."
    #         )
    #         os.system(f"cp {file.path} '{file.name}'")
    #         step.output = (
    #             uploading_status_message + f"âœ… {file.name} uploaded successfully!\n"
    #         )
    #         uploading_status_message = step.output
    #         user_uploaded_system_file += f" - user uploaded data file: {file.name}\n"

    # cl.user_session.set("user_uploaded_system_file", user_uploaded_system_file)

    # # Let the user know that the system is ready
    # await cl.Message(
    #     content=f"{len(files)} files uploaded, total size {sum(file.size for file in files) / (1024 * 1024):.2f} MB!. It is ready to analyze the files."
    # ).send()


@cl.on_chat_resume
async def resume_chat():
    os.chdir(CURRENT_ABS_DIR)
    thread_id = cl.context.session.thread_id
    dir_name = thread_id
    log_dir = f"chainlit_logs/{dir_name}"
    os.makedirs(log_dir, exist_ok=True)

    # Add thread-specific log handler
    add_thread_log_handler(dir_name)

    os.chdir(log_dir)
    print("current dir", os.getcwd())
    logger.info(f"Chat session resumed for thread: {dir_name}")

    # Restore uploaded files from directory
    uploaded_files = []
    if os.path.exists(log_dir):
        # Scan directory for user-uploaded files (exclude system files)
        exclude_files = {"chainlit_stream.log", "conversation_history.txt"}
        for filename in os.listdir(log_dir):
            file_path = os.path.join(log_dir, filename)
            if os.path.isfile(file_path) and filename not in exclude_files:
                uploaded_files.append(filename)

    cl.user_session.set("uploaded_files", uploaded_files)
    if uploaded_files:
        logger.info(
            f"Restored {len(uploaded_files)} uploaded files: {', '.join(uploaded_files)}"
        )


@cl.on_audio_start
async def on_audio_start():
    """Handle start of audio recording.

    This function is called when user starts recording.
    Returns True to allow recording, False to reject.
    """
    # Initialize silence detection state (like reference code)
    cl.user_session.set("silent_duration_ms", 0)
    cl.user_session.set("is_speaking", False)
    cl.user_session.set("audio_chunks", [])  # Use list of numpy arrays like reference

    logger.info("[AUDIO] ===== Recording started =====")
    print("[AUDIO] ===== Recording started =====")

    current_file_path = os.path.dirname(os.path.abspath(__file__))
    reference_data_path = os.path.join(current_file_path, "proteomics.xlsx")
    os.system(f"cp {reference_data_path} .")
    print(f"cp {reference_data_path} .")
    return True


@cl.on_audio_chunk
async def on_audio_chunk(chunk: cl.InputAudioChunk):
    """Handle incoming audio chunks from user's microphone.

    This function is called for each audio chunk received during voice recording.
    Includes silence detection to auto-stop recording after prolonged silence.
    Based on reference implementation from Chainlit cookbook.
    """
    # Get audio chunks list and append current chunk as numpy array
    audio_chunks = cl.user_session.get("audio_chunks")
    if audio_chunks is not None:
        audio_chunk = np.frombuffer(chunk.data, dtype=np.int16)
        audio_chunks.append(audio_chunk)

    # If this is the first chunk, initialize timers and state
    if chunk.isStart:
        cl.user_session.set("last_elapsed_time", chunk.elapsedTime)
        cl.user_session.set("is_speaking", True)
        logger.info("[AUDIO] First chunk received, starting silence detection")
        return

    # Get silence detection state
    last_elapsed_time = cl.user_session.get("last_elapsed_time", 0)
    silent_duration_ms = cl.user_session.get("silent_duration_ms", 0)
    is_speaking = cl.user_session.get("is_speaking", False)

    # Calculate the time difference between this chunk and the previous one
    time_diff_ms = chunk.elapsedTime - last_elapsed_time
    cl.user_session.set("last_elapsed_time", chunk.elapsedTime)

    # Compute the RMS (root mean square) energy of the audio chunk
    audio_energy = audioop.rms(
        chunk.data, 2
    )  # Assumes 16-bit audio (2 bytes per sample)

    if audio_energy < SILENCE_THRESHOLD:
        # Audio is considered silent
        silent_duration_ms += time_diff_ms
        cl.user_session.set("silent_duration_ms", silent_duration_ms)

        if silent_duration_ms >= SILENCE_TIMEOUT_MS and is_speaking:
            cl.user_session.set("is_speaking", False)
            logger.info(
                f"[AUDIO] Silence detected for {silent_duration_ms}ms, auto-processing"
            )
            print(
                f"[AUDIO] Silence detected for {silent_duration_ms}ms, auto-processing"
            )

            # Stop frontend recording by turning off audio connection
            try:
                await cl.context.emitter.update_audio_connection("off")
                logger.info("[AUDIO] Turned off audio connection")
            except Exception as e:
                logger.warning(f"[AUDIO] Failed to turn off audio connection: {e}")

            await process_audio()
    else:
        # Audio is not silent, reset silence timer and mark as speaking
        cl.user_session.set("silent_duration_ms", 0)
        if not is_speaking:
            cl.user_session.set("is_speaking", True)


async def process_audio():
    """Process recorded audio - transcribe and send to agent.

    Based on reference implementation from Chainlit cookbook.
    """
    logger.info("[AUDIO] ===== Processing audio =====")
    print("[AUDIO] ===== Processing audio =====")

    # Get the audio chunks from the session
    audio_chunks = cl.user_session.get("audio_chunks")
    if not audio_chunks:
        logger.warning("[AUDIO] No audio chunks found")
        return

    # Concatenate all chunks
    concatenated = np.concatenate(list(audio_chunks))

    # Create an in-memory binary stream
    wav_buffer = io.BytesIO()

    # Create WAV file with proper parameters
    with wave.open(wav_buffer, "wb") as wav_file:
        wav_file.setnchannels(1)  # mono
        wav_file.setsampwidth(2)  # 2 bytes per sample (16-bit)
        wav_file.setframerate(24000)  # sample rate (24kHz PCM)
        wav_file.writeframes(concatenated.tobytes())

    # Reset buffer position
    wav_buffer.seek(0)

    # Clear audio chunks
    cl.user_session.set("audio_chunks", [])

    # Check duration - skip if too short
    frames = len(concatenated)
    rate = 24000
    duration = frames / float(rate)

    logger.info(f"[AUDIO] Audio duration: {duration:.2f}s, frames: {frames}")
    print(f"[AUDIO] Audio duration: {duration:.2f}s")

    if duration <= 0.5:
        logger.info("[AUDIO] Audio too short, skipping")
        print("[AUDIO] Audio too short, skipping")
        return

    # Show processing indicator
    processing_msg = cl.Message(content="ğŸ¤ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")
    await processing_msg.send()

    try:
        audio_buffer = wav_buffer.getvalue()
        wav_buffer.seek(0)
        wav_buffer.name = "audio.wav"

        # Transcribe audio using OpenAI Whisper API
        transcription = openai_client.audio.transcriptions.create(
            model="whisper-1", file=wav_buffer, language="ko"
        )

        transcribed_text = transcription.text.strip()
        logger.info(f"[AUDIO] Transcription result: {transcribed_text}")

        if not transcribed_text:
            await processing_msg.remove()
            await cl.Message(
                content="ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            ).send()
            return

        # Remove processing indicator
        await processing_msg.remove()

        # Create user message with transcribed text and audio element
        input_audio_el = cl.Audio(content=audio_buffer, mime="audio/wav")
        await cl.Message(
            author="You",
            type="user_message",
            content=transcribed_text,
            elements=[input_audio_el],
        ).send()

        # Create a message object for the main handler
        user_msg = cl.Message(content=transcribed_text)

        # Process the transcribed message through the main handler
        await main(user_msg)

    except Exception as e:
        logger.error(f"[AUDIO] Transcription error: {e}", exc_info=True)
        await processing_msg.remove()
        await cl.Message(content=f"ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}").send()
    finally:
        # Reset state
        cl.user_session.set("silent_duration_ms", 0)
        cl.user_session.set("is_speaking", False)


@cl.on_message
async def main(user_message: cl.Message):
    """
    Handle user messages and process them through the agent.

    Args:
        user_message: The user's message from Chainlit UI.
    """
    print("current dir:", os.getcwd())
    user_data = await _process_user_message(user_message)
    message_history = _update_message_history(user_data)
    agent_input = _convert_to_agent_format(message_history)

    await _process_agent_response(agent_input, message_history)


async def _process_user_message(user_message: cl.Message) -> dict:
    """Process user message and handle file uploads.

    Returns:
        dict with 'text' and optional 'images' keys
    """
    user_prompt = user_message.content.strip()
    images = []

    # Image file extensions
    image_extensions = {
        ".png",
        ".jpg",
        ".jpeg",
        ".gif",
        ".bmp",
        ".webp",
        ".tiff",
        ".tif",
    }

    # PDF file extension
    pdf_extensions = {".pdf"}

    # Video file extensions
    video_extensions = {
        ".mp4",
        ".mov",
        ".avi",
        ".webm",
        ".mkv",
        ".flv",
        ".wmv",
        ".m4v",
    }

    # Audio file extensions
    audio_extensions = {
        ".mp3",
        ".wav",
        ".flac",
        ".ogg",
        ".m4a",
        ".aac",
        ".wma",
        ".opus",
    }

    # Get current uploaded files list from session
    uploaded_files = cl.user_session.get("uploaded_files", [])

    # Process uploaded files
    for file in user_message.elements:
        os.system(f"cp {file.path} '{file.name}'")

        # Add to uploaded files list if not already present
        if file.name not in uploaded_files:
            uploaded_files.append(file.name)

        # Check file extension
        file_ext = os.path.splitext(file.name)[1].lower()
        
        # Process image files
        if file_ext in image_extensions:
            try:
                # Extract image resolution
                img_width, img_height = None, None
                try:
                    with Image.open(file.path) as img:
                        img_width, img_height = img.size
                except Exception as e:
                    print(f"Could not extract image dimensions for {file.name}: {e}")

                # Read image and encode to base64
                with open(file.path, "rb") as f:
                    image_data = base64.b64encode(f.read()).decode("utf-8")

                # Determine MIME type
                mime_type_map = {
                    ".png": "image/png",
                    ".jpg": "image/jpeg",
                    ".jpeg": "image/jpeg",
                    ".gif": "image/gif",
                    ".bmp": "image/bmp",
                    ".webp": "image/webp",
                    ".tiff": "image/tiff",
                    ".tif": "image/tiff",
                }
                mime_type = mime_type_map.get(file_ext, "image/jpeg")

                images.append(
                    {"name": file.name, "data": f"data:{mime_type};base64,{image_data}"}
                )

                # Add image info with resolution to prompt
                if img_width and img_height:
                    user_prompt += f"\n - user uploaded image file: {file.name} (resolution: {img_width}x{img_height} pixels)\n"
                else:
                    user_prompt += f"\n - user uploaded image file: {file.name}\n"
            except Exception as e:
                print(f"Error processing image {file.name}: {e}")
                user_prompt += f"\n - user uploaded data file: {file.name}\n"
        # Process PDF files - encode as base64 like images (Gemini API supports PDF natively)
        elif file_ext in pdf_extensions:
            try:
                # Read PDF and encode to base64 (same way as images)
                with open(file.path, "rb") as f:
                    pdf_data = base64.b64encode(f.read()).decode("utf-8")

                # Add PDF as base64 encoded data with application/pdf MIME type
                images.append(
                    {"name": file.name, "data": f"data:application/pdf;base64,{pdf_data}"}
                )

                # Get PDF page count for info (optional, for logging)
                try:
                    import PyPDF2
                    with open(file.path, "rb") as pdf_file:
                        pdf_reader = PyPDF2.PdfReader(pdf_file)
                        num_pages = len(pdf_reader.pages)
                        user_prompt += f"\n - user uploaded PDF file: {file.name} ({num_pages} pages)\n"
                except Exception:
                    user_prompt += f"\n - user uploaded PDF file: {file.name}\n"
            except Exception as e:
                print(f"Error processing PDF {file.name}: {e}")
                user_prompt += f"\n - user uploaded data file: {file.name}\n"
        # Process video files - encode as base64 (Gemini API supports video natively)
        elif file_ext in video_extensions:
            try:
                # Read video and encode to base64
                with open(file.path, "rb") as f:
                    video_data = base64.b64encode(f.read()).decode("utf-8")

                # Determine MIME type for video
                video_mime_type_map = {
                    ".mp4": "video/mp4",
                    ".mov": "video/quicktime",
                    ".avi": "video/x-msvideo",
                    ".webm": "video/webm",
                    ".mkv": "video/x-matroska",
                    ".flv": "video/x-flv",
                    ".wmv": "video/x-ms-wmv",
                    ".m4v": "video/mp4",
                }
                mime_type = video_mime_type_map.get(file_ext, "video/mp4")

                # Add video as base64 encoded data
                images.append(
                    {"name": file.name, "data": f"data:{mime_type};base64,{video_data}"}
                )

                user_prompt += f"\n - user uploaded video file: {file.name}\n"
            except Exception as e:
                print(f"Error processing video {file.name}: {e}")
                user_prompt += f"\n - user uploaded data file: {file.name}\n"
        # Process audio files - encode as base64 (Gemini API supports audio natively)
        elif file_ext in audio_extensions:
            try:
                # Read audio and encode to base64
                with open(file.path, "rb") as f:
                    audio_data = base64.b64encode(f.read()).decode("utf-8")

                # Determine MIME type for audio
                audio_mime_type_map = {
                    ".mp3": "audio/mpeg",
                    ".wav": "audio/wav",
                    ".flac": "audio/flac",
                    ".ogg": "audio/ogg",
                    ".m4a": "audio/mp4",
                    ".aac": "audio/aac",
                    ".wma": "audio/x-ms-wma",
                    ".opus": "audio/opus",
                }
                mime_type = audio_mime_type_map.get(file_ext, "audio/mpeg")

                # Add audio as base64 encoded data
                images.append(
                    {"name": file.name, "data": f"data:{mime_type};base64,{audio_data}"}
                )

                user_prompt += f"\n - user uploaded audio file: {file.name}\n"
            except Exception as e:
                print(f"Error processing audio {file.name}: {e}")
                user_prompt += f"\n - user uploaded data file: {file.name}\n"
        else:
            user_prompt += f"\n - user uploaded data file: {file.name}\n"

    # Update uploaded files in session
    cl.user_session.set("uploaded_files", uploaded_files)

    # Always append all uploaded files information to the prompt
    # This ensures the AI remembers all files throughout the conversation
    if uploaded_files:
        files_info = (
            "\n\n[System: Available uploaded files in working directory: "
            + ", ".join(uploaded_files)
            + "]"
        )
        user_prompt += files_info

    return {"text": user_prompt, "images": images}


def _update_message_history(user_data: dict) -> list:
    """Update and return message history.

    Args:
        user_data: dict with 'text' and optional 'images' keys
    """
    message_history = cl.user_session.get("message_history", [])
    message_history.append(
        {
            "role": "user",
            "content": user_data["text"],
            "images": user_data.get("images", []),
        }
    )
    return message_history


def _convert_to_agent_format(message_history: list) -> list:
    """Convert message history to agent input format."""
    agent_input = []
    for message in message_history:
        if message["role"] == "user":
            # Check if there are images to include
            images = message.get("images", [])
            if images:
                # Create content as a list with text and images
                content = [{"type": "text", "text": message["content"]}]
                for img in images:
                    content.append(
                        {"type": "image_url", "image_url": {"url": img["data"]}}
                    )
                agent_input.append(HumanMessage(content=content))
            else:
                # Text only
                agent_input.append(HumanMessage(content=message["content"]))
        elif message["role"] == "assistant":
            agent_input.append(AIMessage(content=message["content"]))
    return agent_input


async def _sync_generator_to_async(sync_gen):
    """Convert a sync generator to async generator.

    This allows us to use async for loop which automatically checks
    for CancelledError at each iteration.
    """
    loop = asyncio.get_running_loop()

    def get_next_item():
        try:
            return next(sync_gen)
        except StopIteration:
            return None

    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        while True:
            # Run next() in executor to avoid blocking
            item = await loop.run_in_executor(executor, get_next_item)
            if item is None:
                break
            yield item


def _extract_text_from_content(content):
    """Extract text from message content (handles both string and list formats).

    Args:
        content: Either a string or a list with text and image_url dicts

    Returns:
        str: The text content
    """
    if isinstance(content, str):
        return content
    elif isinstance(content, list):
        # Extract text from list format
        text_parts = []
        for item in content:
            if isinstance(item, dict) and item.get("type") == "text":
                text_parts.append(item.get("text", ""))
        return "".join(text_parts)
    else:
        return str(content)


async def _process_agent_response(agent_input: list, message_history: list):
    """Process agent response and handle streaming."""

    with open(f"conversation_history.txt", "a") as f:
        user_content_text = _extract_text_from_content(agent_input[-1].content)
        f.write(user_content_text + "\n")

    logger.info("[RESPONSE] Starting agent response processing")

    try:
        async with cl.Step(name="Plan and execute") as chainlit_step:
            await chainlit_step.update()
            sync_message_stream = agent.go_stream(agent_input)
            # Convert sync generator to async
            message_stream = _sync_generator_to_async(sync_message_stream)
            full_message, step_message, raw_full_message = await _handle_message_stream(
                message_stream, chainlit_step, sync_message_stream
            )

        final_message = _extract_final_message(raw_full_message)
        final_message = _detect_image_name_and_move_to_public(final_message)

        await cl.Message(content=final_message).send()

        print(os.getcwd())
        print(final_message)

        with open(f"conversation_history.txt", "a") as f:
            f.write(raw_full_message + "\n")
        message_history.append({"role": "assistant", "content": raw_full_message})

        # Save conversation to memory
        try:
            user_message_content = message_history[-2]["content"] # The message before the one we just appended
            save_conversation(user_message_content, final_message)
        except Exception as e:
            logger.error(f"Failed to save conversation to memory: {e}")

    except asyncio.CancelledError:
        # Handle stop button click
        logger.info("User requested to stop the execution")
        # await cl.Message(
        #     content="â¹ï¸ **ì‹¤í–‰ ì¤‘ì§€ë¨**: ì‚¬ìš©ìê°€ ì‹¤í–‰ì„ ì¤‘ì§€í–ˆìŠµë‹ˆë‹¤."
        # ).send()
        message_history.append(
            {"role": "assistant", "content": "ì‹¤í–‰ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."}
        )
        raise  # Re-raise to properly propagate cancellation
    except TimeoutError as e:
        error_message = str(e)
        logger.error(f"Streaming timeout: {error_message}")
        await cl.Message(
            content=f"âš ï¸ **íƒ€ì„ì•„ì›ƒ ë°œìƒ**: {error_message}\n\n"
            f"ìµœëŒ€ ëŒ€ê¸° ì‹œê°„({STREAMING_MAX_TIMEOUT}ì´ˆ)ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. "
            "ë” ì‘ì€ ì‘ì—…ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        ).send()
        message_history.append(
            {"role": "assistant", "content": f"íƒ€ì„ì•„ì›ƒ ë°œìƒ: {error_message}"}
        )
    except Exception as e:
        error_message = f"ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(error_message, exc_info=True)
        error_message = _replace_biomni(error_message)
        await cl.Message(content=f"âŒ **ì˜¤ë¥˜**: {error_message}").send()
        message_history.append({"role": "assistant", "content": error_message})


async def _handle_message_stream(message_stream, chainlit_step, sync_generator):
    """Handle streaming messages from the agent using async for loop.

    This approach is much simpler and automatically handles CancelledError
    at each await point in the async for loop.

    Args:
        message_stream: Async generator (converted from sync)
        chainlit_step: Chainlit Step object
        sync_generator: Original sync generator for cleanup
    """
    raw_full_message = ""
    step_message = ""
    current_step = 1
    last_formatted_text = ""
    image_cache = {}
    last_chunk_time = [
        asyncio.get_event_loop().time()
    ]  # Mutable to share with heartbeat
    stream_done = [False]  # Mutable flag to stop heartbeat
    last_heartbeat_msg = [""]  # Mutable to share with main loop

    logger.info("[STREAM] Starting message stream processing")

    async def heartbeat():
        """Send periodic 'working...' messages if no chunks received for a while."""
        heartbeat_count = 0

        while not stream_done[0]:
            try:
                await asyncio.sleep(2)  # Check every 2 seconds
            except asyncio.CancelledError:
                break

            if stream_done[0]:
                break

            elapsed = asyncio.get_event_loop().time() - last_chunk_time[0]

            # Only show message if waiting > 5 seconds
            if elapsed >= 5:
                heartbeat_count += 1
                elapsed_int = int(elapsed)

                logger.info(
                    f"[HEARTBEAT #{heartbeat_count}] Showing working message (elapsed: {elapsed_int}s)"
                )

                # Create new heartbeat message
                new_msg = f"\n\n_â³ Still working... ({elapsed_int} seconds elapsed)_"

                try:
                    # Get current output and append heartbeat
                    current_output = chainlit_step.output or last_formatted_text

                    # Remove old heartbeat if present
                    if last_heartbeat_msg[0] and current_output.endswith(
                        last_heartbeat_msg[0]
                    ):
                        current_output = current_output[: -len(last_heartbeat_msg[0])]

                    # Set new output with heartbeat
                    chainlit_step.output = current_output + new_msg
                    await chainlit_step.update()  # UI ì—…ë°ì´íŠ¸ í•„ìˆ˜!
                    last_heartbeat_msg[0] = new_msg
                    logger.debug(f"[HEARTBEAT] Updated output with message")
                except Exception as e:
                    logger.warning(f"[HEARTBEAT] Failed to update: {e}")
            else:
                # Silent heartbeat for debugging
                logger.debug(
                    f"[HEARTBEAT] Check (elapsed: {elapsed:.1f}s, waiting for 5s)"
                )

    # Start heartbeat task
    heartbeat_task = asyncio.create_task(heartbeat())

    try:
        # async for automatically checks for CancelledError at each iteration!
        async for chunk in message_stream:
            # Update last chunk time
            last_chunk_time[0] = asyncio.get_event_loop().time()
            # At this await point, CancelledError is automatically raised
            # if the task is cancelled (page refresh or stop button)

            this_step = chunk[1][1]["langgraph_step"]
            if this_step != current_step:
                step_message = ""
                current_step = this_step

            chunk_content = _extract_chunk_content(chunk)
            if chunk_content is None:
                continue

            if not isinstance(chunk_content, str):
                chunk_content = chunk_content[0]["text"] + "\n"

            raw_full_message += chunk_content
            step_message += chunk_content

            # Remove heartbeat message if present (new chunk arrived!)
            if last_heartbeat_msg[0]:
                logger.debug("[STREAM] Removing heartbeat message (new chunk arrived)")
                current_output = chainlit_step.output or ""
                if current_output.endswith(last_heartbeat_msg[0]):
                    chainlit_step.output = current_output[: -len(last_heartbeat_msg[0])]
                last_heartbeat_msg[0] = ""  # Clear heartbeat message

            # Format and detect images
            formatted_text = _modify_chunk(raw_full_message)
            formatted_text = _detect_image_name_and_move_to_public(
                formatted_text, image_cache
            )

            # Only stream if changed
            if formatted_text != last_formatted_text:
                prev_output = last_formatted_text

                if prev_output and formatted_text.startswith(prev_output):
                    delta = formatted_text[len(prev_output) :]
                else:
                    delta = formatted_text

                if delta:
                    # This await also checks for CancelledError
                    await chainlit_step.stream_token(delta)
                    chainlit_step.output = formatted_text
                    last_formatted_text = formatted_text

        logger.info("[STREAM] Stream completed successfully")

        # Stop heartbeat
        stream_done[0] = True

        # Remove any remaining heartbeat message
        if last_heartbeat_msg[0]:
            logger.debug("[STREAM] Removing heartbeat message at completion")
            current_output = chainlit_step.output or ""
            if current_output.endswith(last_heartbeat_msg[0]):
                chainlit_step.output = current_output[: -len(last_heartbeat_msg[0])]
            last_heartbeat_msg[0] = ""

        # Final formatting
        full_formatted = _modify_chunk(raw_full_message)
        full_formatted = _detect_image_name_and_move_to_public(
            full_formatted, image_cache
        )

        # Final update if needed
        if full_formatted != last_formatted_text:
            remaining_delta = (
                full_formatted[len(last_formatted_text) :]
                if last_formatted_text
                and full_formatted.startswith(last_formatted_text)
                else full_formatted
            )
            if remaining_delta:
                await chainlit_step.stream_token(remaining_delta)
                chainlit_step.output = full_formatted

        step_message = _modify_chunk(step_message)
        step_message = _detect_image_name_and_move_to_public(step_message, image_cache)

        return full_formatted, step_message, raw_full_message

    except asyncio.CancelledError:
        logger.info("[STREAM] CancelledError - closing generator and stopping")
        stream_done[0] = True

        # Close the sync generator explicitly to clean up resources
        if sync_generator and hasattr(sync_generator, "close"):
            try:
                sync_generator.close()
                logger.info("[STREAM] Sync generator closed successfully")
            except Exception as e:
                logger.warning(f"[STREAM] Failed to close generator: {e}")
        raise  # Re-raise to propagate cancellation

    except Exception as e:
        logger.error(f"[STREAM] Error during streaming: {e}", exc_info=True)
        stream_done[0] = True

        # Also close generator on error
        if sync_generator and hasattr(sync_generator, "close"):
            try:
                sync_generator.close()
            except:
                pass
        raise

    finally:
        # Always stop and cleanup heartbeat task
        stream_done[0] = True
        if heartbeat_task and not heartbeat_task.done():
            heartbeat_task.cancel()
            try:
                await heartbeat_task
            except asyncio.CancelledError:
                pass


def _extract_chunk_content(chunk):
    """Extract content from chunk based on node type."""
    node = chunk[1][1]["langgraph_node"]
    chunk_data = chunk[1][0]

    if node == "generate" and isinstance(chunk_data, AIMessageChunk):
        return chunk_data.content
    elif node == "execute":
        return chunk_data.content
    else:
        return None


def _extract_final_message(step_message: str) -> str:
    """Extract final message from the last <solution> tag pair."""
    # Close unclosed solution tag if needed
    if "<solution>" in step_message and "</solution>" not in step_message:
        step_message += "</solution>"

    # Find all solution tag matches
    solution_matches = list(
        re.finditer(r"<solution>(.*?)</solution>", step_message, re.DOTALL)
    )

    # Return content from the last match, or original message if no match found
    if solution_matches:
        return solution_matches[-1].group(1).strip()
    else:
        return step_message


def _detect_code_type(code: str) -> str:
    """
    Detect code type based on markers and content.

    Args:
        code: Code content to analyze

    Returns:
        Code type string for markdown code block (python, r, bash)
    """
    code_stripped = code.strip()

    # Check for explicit markers
    if (
        code_stripped.startswith("#!R")
        or code_stripped.startswith("# R code")
        or code_stripped.startswith("# R script")
    ):
        return "r"
    elif (
        code_stripped.startswith("#!BASH")
        or code_stripped.startswith("# Bash script")
        or code_stripped.startswith("#!CLI")
    ):
        return "bash"

    # Heuristic detection based on common patterns
    # R patterns
    r_patterns = [
        r"\blibrary\(",
        r"\brequire\(",
        r"<-",
        r"\$",
        r"\.R\b",
        r"\bdata\.frame\(",
        r"\bggplot\(",
        r"\bc\(",
    ]

    # Bash patterns
    bash_patterns = [
        r"^#!",
        r"\becho\b",
        r"\bls\b",
        r"\bcd\b",
        r"\bmkdir\b",
        r"\bcp\b",
        r"\bmv\b",
        r"\brm\b",
        r"\bgrep\b",
        r"\bawk\b",
        r"\bsed\b",
        r"\|\s*\w+",  # pipe commands
    ]

    # Count pattern matches
    r_score = sum(1 for pattern in r_patterns if re.search(pattern, code_stripped))
    bash_score = sum(
        1 for pattern in bash_patterns if re.search(pattern, code_stripped)
    )

    # Determine code type based on scores
    if r_score > 0 and r_score >= bash_score:
        return "r"
    elif bash_score > 0:
        return "bash"
    else:
        return "python"  # Default to python


def _modify_chunk(chunk: str) -> str:
    """Modify chunk content by replacing tags."""
    retval = chunk

    # First, handle observation tags with proper formatting
    # This prevents backticks and other special characters from being misinterpreted as markdown
    observation_pattern = r"<observation>(.*?)</observation>"

    def format_observation(match):
        observation_content = match.group(1).strip()

        # Check if it's an error message
        is_error = any(
            keyword in observation_content
            for keyword in [
                "Error",
                "error",
                "Exception",
                "Traceback",
                "Failed",
                "Execution halted",
            ]
        )

        if is_error:
            return f"\n\n**âŒ Execution Error:**\n```\n{observation_content}\n```\n"

        # Check if observation contains file listings (CSV or other files)
        has_file_listings = (
            "**Newly created files:**" in observation_content
            or "**Other files:**" in observation_content
        )

        if has_file_listings:
            # Split into text before files and file section
            lines = observation_content.split("\n")
            text_before_files = []
            file_section_start = -1

            # Find where file section starts
            for i, line in enumerate(lines):
                if "**Newly created files:**" in line or "**Other files:**" in line:
                    file_section_start = i
                    break
                text_before_files.append(line)

            # Format text before files (regular text, not in code block)
            formatted_text = "\n".join(text_before_files).strip()

            # Format file section
            if file_section_start >= 0:
                file_section = "\n".join(lines[file_section_start:])

                # Detect CSV content in file section (lines with many commas)
                file_lines = file_section.split("\n")
                formatted_file_lines = []
                csv_block_lines = []
                in_csv_block = False

                for line in file_lines:
                    # Check if line looks like CSV data (starts with comma or has many commas)
                    is_csv_line = line.strip().startswith(",") or (
                        "," in line and line.count(",") >= 3
                    )

                    if is_csv_line:
                        if not in_csv_block:
                            # Start new CSV block
                            in_csv_block = True
                        csv_block_lines.append(line)
                    else:
                        if in_csv_block:
                            # End CSV block - format and add it
                            if csv_block_lines:
                                csv_lines = csv_block_lines[:10]
                                if len(csv_block_lines) > 10:
                                    csv_lines.append("... (truncated: more lines)")
                                csv_content = "\n".join(csv_lines)
                                formatted_file_lines.append(
                                    f"```csv\n{csv_content}\n```"
                                )
                                csv_block_lines = []
                            in_csv_block = False
                        formatted_file_lines.append(line)

                # Handle remaining CSV block
                if csv_block_lines:
                    csv_lines = csv_block_lines[:10]
                    if len(csv_block_lines) > 10:
                        csv_lines.append("... (truncated: more lines)")
                    csv_content = "\n".join(csv_lines)
                    formatted_file_lines.append(f"```csv\n{csv_content}\n```")

                formatted_file_section = "\n".join(formatted_file_lines)

                # Combine formatted text and file section
                if formatted_text:
                    return f"\n\n**âœ… Execution Result:**\n\n{formatted_text}\n\n{formatted_file_section}\n"
                else:
                    return f"\n\n**âœ… Execution Result:**\n\n{formatted_file_section}\n"
            else:
                # No file section found, format as regular text
                return f"\n\n**âœ… Execution Result:**\n\n{formatted_text}\n"
        else:
            # No file listings, format as regular code block
            return f"\n\n**âœ… Execution Result:**\n```\n{observation_content}\n```\n"

    retval = re.sub(observation_pattern, format_observation, retval, flags=re.DOTALL)

    # Then handle other tags
    tag_replacements = [
        ("<execute>", "\n```CODE_TYPE\n"),
        ("</execute>", "```\n"),
        ("<solution>", ""),
        ("</solution>", ""),
    ]

    for tag1, tag2 in tag_replacements:
        if tag1 in retval:
            retval = retval.replace(tag1, tag2)

    # Handle existing CODE_TYPE placeholders in already generated code blocks
    retval = _replace_code_type_placeholders(retval)

    # Replace biomni imports with hits imports in code blocks
    retval = _replace_biomni(retval)

    return retval


def _replace_code_type_placeholders(content: str) -> str:
    """Replace CODE_TYPE placeholders with detected code types."""
    # Pattern to find code blocks with CODE_TYPE placeholder
    code_type_pattern = r"```CODE_TYPE\n(.*?)```"

    def replace_code_type(match):
        code_content = match.group(1)
        code_type = _detect_code_type(code_content)
        return f"```{code_type}\n{code_content}```"

    # Handle closed code blocks with CODE_TYPE
    content = re.sub(code_type_pattern, replace_code_type, content, flags=re.DOTALL)

    # Handle open code blocks that start with ```CODE_TYPE
    open_code_pattern = r"```CODE_TYPE\n(.*?)(?=```|\Z)"

    def replace_open_code_type(match):
        code_content = match.group(1)
        code_type = _detect_code_type(code_content)
        return f"```{code_type}\n{code_content}"

    content = re.sub(
        open_code_pattern, replace_open_code_type, content, flags=re.DOTALL
    )

    return content


def _replace_biomni(content: str) -> str:
    """Replace all occurrences of 'biomni' and 'Biomni' with 'hits' in code blocks and text."""
    # Pattern to find code blocks (both with specific language and generic)
    code_block_pattern = r"```(\w+)?\n(.*?)```"

    def replace_imports_in_code(match):
        language = match.group(1) if match.group(1) else ""
        code_content = match.group(2)

        # Replace ALL occurrences, case-insensitive for biomni
        modified_code = re.sub(r"\bbiomni\b", "hits", code_content, flags=re.IGNORECASE)
        # Also handle lowercase/uppercase word-boundary safe (edge: Biomni in class names etc.)
        # But above regex with IGNORECASE handles both "biomni" and "Biomni"

        if language:
            return f"```{language}\n{modified_code}```"
        else:
            return f"```\n{modified_code}```"

    # Apply replacement to all code blocks
    content = re.sub(
        code_block_pattern, replace_imports_in_code, content, flags=re.DOTALL
    )

    # Additional replacements for text outside code blocks:
    # 1. Replace 'biomni.' pattern (e.g., biomni.tool.omics -> hits.tool.omics)
    content = re.sub(r"biomni\.", "hits.", content, flags=re.IGNORECASE)

    # 2. Replace biomni/Biomni in paths and general text with 'hits'
    # This handles cases like /home/ec2-user/Biomni_HITS/... -> /home/ec2-user/hits_HITS/...
    # Also handles biomni_hits_test -> hits_hits_test
    content = re.sub(r"biomni", "hits", content, flags=re.IGNORECASE)

    return content


def _detect_image_name_and_move_to_public(
    content: str, image_cache: dict = None
) -> str:
    """
    Detect images in markdown text, move them to public folder with random prefix.

    Args:
        content: Markdown text content
        image_cache: Dictionary to cache already moved images {original_path: public_path}

    Returns:
        Modified markdown text with updated image paths
    """
    if image_cache is None:
        image_cache = {}

    public_dir = PUBLIC_DIR
    os.makedirs(public_dir, exist_ok=True)

    # Pattern to find markdown images, excluding those already with download functionality
    image_pattern = (
        r'(?<!\[)!\[([^\]]*)\]\(([^)]+?)(?:\s+"[^"]*")?\)(?!\]\([^\)]*\)<br>)'
    )

    def replace_image(match):
        alt_text = match.group(1)
        image_path = match.group(2).strip()

        # Skip URLs
        if image_path.startswith(("http://", "https://")):
            return match.group(0)

        # Add download functionality if already in public folder
        if image_path.startswith(("./public/", "public/", "/public/")):
            # Normalize to absolute path
            if not image_path.startswith("/public/"):
                image_path = "/public/" + image_path.replace("./public/", "").replace(
                    "public/", ""
                )
            file_name = os.path.basename(image_path)
            return (
                f"[![{alt_text}]({image_path})]({image_path})<br>"
                f'<a href="{image_path}" download="{file_name}">Download</a>'
            )

        # Check if file exists
        if not os.path.exists(image_path):
             # Try to find it relative to the current working directory (chainlit_logs/thread_id)
             # or relative to the project root (CURRENT_ABS_DIR)
            
            # 1. Check relative to CWD (already done by exists check if path is relative, but explicit check for absolute path construction might be needed)
            cwd_path = os.path.abspath(image_path)
            if os.path.exists(cwd_path):
                image_path = cwd_path
            else:
                # 2. Check relative to CURRENT_ABS_DIR (project root where run.py is, or parent of it)
                # Note: CURRENT_ABS_DIR in this file is chainlit/ directory. 
                # But the agent execution happens in chainlit_logs/{thread_id}. 
                # Sometimes paths are relative to project root.
                
                # Try relative to project root (parent of chainlit dir)
                project_root = os.path.dirname(CURRENT_ABS_DIR)
                root_path = os.path.join(project_root, image_path)
                if os.path.exists(root_path):
                    image_path = root_path
                
        if not os.path.exists(image_path):
            return match.group(0)

        # Check cache first to avoid duplicate copies
        if image_path in image_cache:
            public_path = image_cache[image_path]
            file_name = os.path.basename(public_path)
            return (
                f"[![{alt_text}]({public_path})]({public_path})<br>"
                f'<a href="{public_path}" download="{file_name}">Download</a>'
            )

        # Generate random prefix and new filename
        random_prefix = "".join(
            random.choices(string.ascii_lowercase + string.digits, k=6)
        )
        file_name = os.path.basename(image_path)
        new_file_name = f"{random_prefix}_{file_name}"
        new_file_path = os.path.join(public_dir, new_file_name)

        try:
            shutil.copy2(image_path, new_file_path)
            public_path = f"/public/{new_file_name}"
            image_cache[image_path] = public_path  # Cache the result
            print("copied image to", new_file_path)
            return (
                f"[![{alt_text}]({public_path})]({public_path})<br>"
                f'<a href="{public_path}" download="{new_file_name}">Download</a>'
            )
        except Exception as e:
            print(f"Error moving image {image_path}: {e}")
            return match.group(0)

    return re.sub(image_pattern, replace_image, content)